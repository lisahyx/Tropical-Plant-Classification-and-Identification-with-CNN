{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Import"],"metadata":{"id":"WwGhumKm-5oF"}},{"cell_type":"code","source":["import pandas as pd\n","from PIL import Image\n","from io import BytesIO\n","import requests\n","import numpy as np\n","\n","from skimage.io import imshow, imread\n","from skimage.color import rgb2gray\n","from skimage.filters import threshold_otsu\n","from skimage.morphology import closing\n","from skimage.measure import label, regionprops, regionprops_table\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import os\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import tensorflow as tf\n","from keras.applications.vgg19 import preprocess_input"],"metadata":{"id":"GaEcGiOpm-th"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Dataset"],"metadata":{"id":"e9x6X57D-9I2"}},{"cell_type":"code","source":["df = pd.read_csv('all_combined_460.csv')"],"metadata":{"id":"y_9pAxkKmtpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize lists to store images and labels\n","images = []\n","labels = []\n","\n","for index, row in df.iterrows():\n","    image_url = row['image_url']\n","    label = row['scientific_name']  # Adjust the column name according to your CSV\n","\n","    response = requests.get(image_url)\n","\n","    if response.status_code == 200:\n","        # Load the image using PIL\n","        img = Image.open(BytesIO(response.content))\n","        # Preprocess the image (e.g., resizing, normalization, etc.)\n","        img = img.resize((224, 224))  # Adjust the size as needed\n","        img = np.array(img) / 255.0  # Normalize pixel values\n","        images.append(img)\n","        labels.append(label)\n","\n","# Convert lists to numpy arrays\n","images = np.array(images)\n","labels = np.array(labels)"],"metadata":{"id":"QQ1JR6VDm0mI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Steps"],"metadata":{"id":"ny7q_WuXjc3U"}},{"cell_type":"code","source":["from skimage import exposure, img_as_ubyte\n","\n","def preprocess_image(img):\n","    # Normalize the image\n","    img_normalized = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","    # Convert to grayscale\n","    img_gray = cv2.cvtColor(img_normalized, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Bilateral filter to reduce noise\n","    img_blurred = cv2.bilateralFilter(img_gray, d=9, sigmaColor=75, sigmaSpace=75)\n","\n","    return img_gray, img_blurred"],"metadata":{"id":"njjE3XoMjccn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_image_NDI(img):\n","    # Normalize the image\n","    img_normalized = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","    # Apply Bilateral filter to reduce noise\n","    img_blurred = cv2.bilateralFilter(img_normalized, d=9, sigmaColor=75, sigmaSpace=75)\n","\n","    # Calculate NDI\n","    green_channel = img_blurred[:, :, 1].astype(np.float32)\n","    red_channel = img_blurred[:, :, 2].astype(np.float32)\n","\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        ndi = np.true_divide(green_channel - red_channel, green_channel + red_channel)\n","        ndi[~np.isfinite(ndi)] = 0\n","\n","    # Scale NDI to 0-255 range\n","    img_ndi = ((ndi + 1) * 127.5).astype(np.uint8)\n","\n","    # Replicate the single channel to create a 3-channel image\n","    img_ndi_bgr = cv2.merge((img_ndi, img_ndi, img_ndi))\n","\n","    # Convert NDI image to grayscale for visualization\n","    img_gray = cv2.cvtColor(img_ndi_bgr, cv2.COLOR_BGR2GRAY)\n","\n","    return img_normalized, img_gray\n"],"metadata":{"id":"9OJ9irjbvH-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def contrast_enhancement(img_blurred, method='clahe', limit='0.01'):\n","    if method == 'clahe':\n","        # Apply CLAHE for contrast enhancement\n","        clahe = cv2.createCLAHE(clipLimit=limit, tileGridSize=(8, 8))\n","        img_clahe = clahe.apply(img_blurred)\n","        return img_clahe\n","    else:\n","        raise ValueError(\"Invalid method. Choose either 'clahe'.\")"],"metadata":{"id":"HkFLQUEsv0Uo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_morphological_closing(img, kernel_size=(5, 5)):\n","    # Create a kernel for morphological closing\n","    kernel = np.ones(kernel_size, np.uint8)\n","\n","    # Apply morphological closing\n","    img_morphology = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n","\n","    return img_morphology"],"metadata":{"id":"ZftRFCq2xcV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_and_draw_contours(img_thresh):\n","    contours, _ = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    img_contour = cv2.drawContours(img.copy(), contours, -1, (0,255,0), 3)\n","\n","    return contours, len(contours), img_contour"],"metadata":{"id":"Y9nczYgYjnGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_contours(contours, center, area_threshold, proximity_threshold):\n","    filtered_contours = []\n","    for contour in contours:\n","        if (cv2.contourArea(contour) > area_threshold and\n","            cv2.pointPolygonTest(contour, tuple(center), False) <= proximity_threshold):\n","            filtered_contours.append(contour)\n","    return filtered_contours"],"metadata":{"id":"lQsku3_41Y13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def segment_image(img, contours):\n","    # Create an empty mask (single-channel)\n","    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n","\n","    # Draw filled contours on the mask\n","    cv2.drawContours(mask, contours, -1, (255), cv2.FILLED)\n","\n","    # Apply the mask to the original image\n","    segmented_image = cv2.bitwise_and(img, img, mask=mask)\n","\n","    segmented_image_uint8 = img_as_ubyte(segmented_image)\n","\n","    return segmented_image_uint8\n"],"metadata":{"id":"7NfBmcf_aL5M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plot"],"metadata":{"id":"cc2IBAVKm5gS"}},{"cell_type":"code","source":["def plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours):\n","\n","    axs[idx, 0].imshow(img_gray, cmap='gray')\n","    axs[idx, 0].axis('off')\n","    axs[idx, 0].set_title(f\"Grayscale Image {idx+1}\")\n","\n","    axs[idx, 1].imshow(img_blurred, cmap='gray')\n","    axs[idx, 1].axis('off')\n","    axs[idx, 1].set_title(f\"Blurred Image {idx+1}\")\n","\n","    axs[idx, 2].imshow(img_equalized, cmap='gray')\n","    axs[idx, 2].axis('off')\n","    axs[idx, 2].set_title(f\"Equalized Image {idx+1}\")\n","\n","    axs[idx, 3].imshow(img_morphology, cmap='gray')\n","    axs[idx, 3].axis('off')\n","    axs[idx, 3].set_title(f\"Morphology Image {idx+1}\")\n","\n","    axs[idx, 4].imshow(img_thresh, cmap='gray')\n","    axs[idx, 4].axis('off')\n","    axs[idx, 4].set_title(f\"Thresh Image {idx+1}\")\n","\n","    axs[idx, 5].imshow(img_contour)\n","    axs[idx, 5].axis('off')\n","    axs[idx, 5].set_title(f\"Contour Image {idx+1}\\nNumber of contours: {num_contours}\")\n","\n","    axs[idx, 6].imshow(segmented_image.astype(np.uint8))\n","    axs[idx, 6].axis('off')\n","    axs[idx, 6].set_title(f\"Segmented Image {idx+1}\")"],"metadata":{"id":"O0L71_Q-m8Hz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Otsu Thresholding"],"metadata":{"id":"mWQ-2mYgoSRr"}},{"cell_type":"code","source":["def otsu_thresh(img):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Apply Otsu's thresholding\n","    _, img_thresh = cv2.threshold(img_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","    # Calculate Otsu's threshold value\n","    otsu_threshold_value = cv2.threshold(img_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]\n","\n","    # Display the value\n","    print(\"Global Threshold Value:\", otsu_threshold_value)\n","\n","    return img_thresh"],"metadata":{"id":"B-r5nmkWji63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = otsu_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    # filter contour\n","    center = (100, 100)  # center point\n","    area_threshold = 1000  # area threshold\n","    proximity_threshold = 100  # proximity threshold\n","    filtered_contours = filter_contours(contours, center, area_threshold, proximity_threshold)\n","\n","    segmented_image = segment_image(img, filtered_contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_jyNDbLzcUa07jvmrGr-Av1EkcWOuXfQ"},"id":"JyX9uSOXnHT1","executionInfo":{"status":"ok","timestamp":1710058711439,"user_tz":-480,"elapsed":24655,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"8201a7cb-48a4-4ba5-f731-cbfb6b569a78"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Otsu Split 1/4"],"metadata":{"id":"bw4Vg_7hsPtl"}},{"cell_type":"code","source":["def otsu_split_thresh(img):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Split the image into four vertical parts\n","    h, w = img_uint8.shape\n","    img_parts = [\n","        img_uint8[:, :w//4],\n","        img_uint8[:, w//4:w//2],\n","        img_uint8[:, w//2:3*w//4],\n","        img_uint8[:, 3*w//4:]\n","    ]\n","\n","    # Apply Otsu's thresholding\n","    img_thresh_parts = []\n","    for part in img_parts:\n","        _, img_thresh = cv2.threshold(part, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","        # Calculate Otsu's threshold value\n","        otsu_threshold_value = cv2.threshold(part, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]\n","\n","        img_thresh_parts.append(img_thresh)\n","\n","    # Concatenate the thresholded parts back into a single image\n","    img_thresh_combined = np.concatenate(img_thresh_parts, axis=1)\n","\n","    return img_thresh_combined"],"metadata":{"id":"mq2fqFOGpnj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = otsu_split_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    # filter contour\n","    center = (100, 100)  # center point\n","    area_threshold = 1000  # area threshold\n","    proximity_threshold = 100  # proximity threshold\n","    filtered_contours = filter_contours(contours, center, area_threshold, proximity_threshold)\n","\n","    segmented_image = segment_image(img, filtered_contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"14m5jc2l1TmhUUw1BjIdqvjcUSys3Bmen"},"id":"5fROZur0qNwO","executionInfo":{"status":"ok","timestamp":1710056364143,"user_tz":-480,"elapsed":17316,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"d72e0bd1-d83c-48d7-ee22-a4c4f471d733"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Otsu with NDI"],"metadata":{"id":"mua64eeGyXIQ"}},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image_NDI(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = otsu_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    # filter contour\n","    center = (100, 100)  # center point\n","    area_threshold = 1000  # area threshold\n","    proximity_threshold = 100  # proximity threshold\n","    filtered_contours = filter_contours(contours, center, area_threshold, proximity_threshold)\n","\n","    segmented_image = segment_image(img, filtered_contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1mfFdI7TvRQCiZXr2jKHcvS0bfEbIqwhp"},"id":"sJLFe8JryHcX","executionInfo":{"status":"ok","timestamp":1710058762334,"user_tz":-480,"elapsed":19654,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"e617312d-19c6-495d-dbcf-b5e5021e8297"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Adaptive Mean"],"metadata":{"id":"SRDKXJCXTtlT"}},{"cell_type":"code","source":["def adaptive_mean_thresh(img):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Apply adaptive thresholding (mean)\n","    img_thresh = cv2.adaptiveThreshold(img_uint8, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 199, 5)\n","\n","    return img_thresh"],"metadata":{"id":"OWH286LNqksl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = adaptive_mean_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wuwpzFTB63TAt4YU3mu3ttvuszCWP4Ks"},"id":"5Z2nPLpxq7z8","executionInfo":{"status":"ok","timestamp":1710056430191,"user_tz":-480,"elapsed":20765,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"80498611-84b2-4798-9f95-4167244f1164"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Adaptive Mean Split"],"metadata":{"id":"SJJ3vJZ8H1QH"}},{"cell_type":"code","source":["def adaptive_mean_split_thresh(img):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Split the image into four vertical parts\n","    h, w = img_uint8.shape\n","    img_parts = [\n","        img_uint8[:, :w//4],\n","        img_uint8[:, w//4:w//2],\n","        img_uint8[:, w//2:3*w//4],\n","        img_uint8[:, 3*w//4:]\n","    ]\n","\n","    # Apply adaptive thresholding to each part\n","    img_thresh_parts = []\n","    for part in img_parts:\n","        img_thresh = cv2.adaptiveThreshold(part, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 199, 5)\n","        img_thresh_parts.append(img_thresh)\n","\n","    # Concatenate the thresholded parts back into a single image\n","    img_thresh_combined = np.concatenate(img_thresh_parts, axis=1)\n","\n","    return img_thresh_combined"],"metadata":{"id":"j5Y5fk0qrV8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = adaptive_mean_split_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19RWfVZ2ly93NOlkJU74SYaMKQfINVml5"},"id":"RhNf79lLrWES","executionInfo":{"status":"ok","timestamp":1710052871184,"user_tz":-480,"elapsed":15210,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"e388ab10-323a-43de-c55e-26c208376a1b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Adaptive Mean with NDI"],"metadata":{"id":"9PhB_pYuy5DM"}},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image_NDI(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = adaptive_mean_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1mYPAXGKA-l8yjxZnTGeUOX--YXe7VNpO"},"id":"D8YRxCz-y9TF","executionInfo":{"status":"ok","timestamp":1710056559548,"user_tz":-480,"elapsed":11796,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"d128128d-6748-468e-f31f-19cb7906ac26"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Adaptive Gaussian"],"metadata":{"id":"tZzJ6Dwimup9"}},{"cell_type":"code","source":["def adaptive_gaussian_thresh(img):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Apply adaptive thresholding (mean)\n","    img_thresh = cv2.adaptiveThreshold(img_uint8, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 299, 5)\n","\n","    return img_thresh"],"metadata":{"id":"l2xA8Ys0r3WU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = adaptive_gaussian_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1OJkc9UBCHv_Uv5YyeCR7OWR_8C2_ZePl"},"id":"Ac2LGcKTr3f1","executionInfo":{"status":"ok","timestamp":1710056472985,"user_tz":-480,"elapsed":17927,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"d067e065-c3ac-4c8b-875e-d90cbad43161"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Adaptive Gaussian Split"],"metadata":{"id":"p-_KfjIgtMyM"}},{"cell_type":"code","source":["def adaptive_gaussian_split_thresh(img):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Split the image into four vertical parts\n","    h, w = img_uint8.shape\n","    img_parts = [\n","        img_uint8[:, :w//4],\n","        img_uint8[:, w//4:w//2],\n","        img_uint8[:, w//2:3*w//4],\n","        img_uint8[:, 3*w//4:]\n","    ]\n","\n","    # Apply adaptive thresholding to each part\n","    img_thresh_parts = []\n","    for part in img_parts:\n","        img_thresh = cv2.adaptiveThreshold(part, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 199, 5)\n","        img_thresh_parts.append(img_thresh)\n","\n","    # Concatenate the thresholded parts back into a single image\n","    img_thresh_combined = np.concatenate(img_thresh_parts, axis=1)\n","\n","    return img_thresh_combined"],"metadata":{"id":"SxmHvNqGse0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = adaptive_gaussian_split_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1rSJbQUNvSvodvn5oGQn7W6cY-ArT7E2N"},"id":"JZpAzOVuse5B","executionInfo":{"status":"ok","timestamp":1710058909697,"user_tz":-480,"elapsed":17874,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"95e24df9-5a8d-4e80-84e6-5f3b7d819799"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Adaptive Gaussian with NDI"],"metadata":{"id":"SZWBqLaK0hHZ"}},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image_NDI(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_thresh = adaptive_gaussian_thresh(img_morphology)\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1w9Gs1EQs8PLSsptbBT0mpsW-3LppZZoE"},"id":"xTZEWH8C0hby","executionInfo":{"status":"ok","timestamp":1710052948745,"user_tz":-480,"elapsed":14722,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"88a513fa-29f6-4918-a987-a6a3b9c42edd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Rosin Threshold"],"metadata":{"id":"tdkiI3WKvjxp"}},{"cell_type":"code","source":["def rosin_threshold(image, k):\n","    hist, _ = np.histogram(image.flatten(), bins=256, range=(0, 256))\n","\n","    threshold = 0\n","    done = False\n","    while not done:\n","        histogram_left = np.sum(hist[:threshold])\n","        histogram_right = np.sum(hist[threshold:])\n","\n","        sum_left = np.sum(hist[:threshold] * np.arange(threshold))\n","        sum_right = np.sum(hist[threshold:] * np.arange(threshold, 256))\n","\n","        mean_left = sum_left / (histogram_left + 1e-6)  # Avoid division by zero\n","        mean_right = sum_right / (histogram_right + 1e-6)  # Avoid division by zero\n","\n","        threshold_next = int((mean_left + mean_right) / 2)\n","\n","        if abs(threshold - threshold_next) <= k:\n","            done = True\n","        else:\n","            threshold = threshold_next\n","\n","    _, thresholded_img = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n","\n","    return thresholded_img"],"metadata":{"id":"CljZa0wyhnmK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_morphology_uint8 = cv2.normalize(img_morphology, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","    img_thresh = rosin_threshold(img_morphology_uint8, 5)\n","\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JT_7s6QPH0ZkMBR0ufFFa_eFnILiJRkj"},"id":"aGxi0euilyIG","executionInfo":{"status":"ok","timestamp":1710052956789,"user_tz":-480,"elapsed":8049,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"1173928a-c397-40ac-f4e7-0c845905f48f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Rosin Split 1/4"],"metadata":{"id":"p_S6Xce-p1Lq"}},{"cell_type":"code","source":["def rosin_thresh_split(img, k):\n","    # Convert to 8-bit unsigned integer\n","    img_uint8 = img_as_ubyte(img)\n","\n","    # Split the image into four vertical parts\n","    h, w = img_uint8.shape\n","    img_parts = [\n","        img_uint8[:, :w//4],\n","        img_uint8[:, w//4:w//2],\n","        img_uint8[:, w//2:3*w//4],\n","        img_uint8[:, 3*w//4:]\n","    ]\n","\n","    # Apply adaptive thresholding to each part\n","    img_thresh_parts = []\n","    for part in img_parts:\n","        img_thresh = rosin_threshold(part, k)\n","        img_thresh_parts.append(img_thresh)\n","\n","    # Concatenate the thresholded parts back into a single image\n","    img_thresh_combined = np.concatenate(img_thresh_parts, axis=1)\n","\n","    return img_thresh_combined"],"metadata":{"id":"1tQ-pF3Np5om"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_morphology_uint8 = cv2.normalize(img_morphology, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","    img_thresh = rosin_thresh_split(img_morphology_uint8, 5)\n","\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uv43WZG3-GMb1eeRg_cai31qFRGPaByg"},"id":"_ymv3PLZxJka","executionInfo":{"status":"ok","timestamp":1710052964895,"user_tz":-480,"elapsed":8119,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"68127614-53f9-4fe9-d10b-9cce32bd9f80"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Rosin with NDI"],"metadata":{"id":"1UqINTgT0ucO"}},{"cell_type":"code","source":["# Load the first ten images\n","ten_images = images[:10]\n","\n","# Create the figure and axes outside the loop\n","fig, axs = plt.subplots(10, 7, figsize=(20, 20))\n","\n","for idx, img in enumerate(ten_images):\n","    img_gray, img_blurred = preprocess_image_NDI(img)\n","    img_equalized = contrast_enhancement(img_blurred, method='clahe', limit=0.01)\n","    img_morphology = apply_morphological_closing(img_equalized, kernel_size=(5, 5))\n","    img_morphology_uint8 = cv2.normalize(img_morphology, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","    img_thresh = rosin_threshold(img_morphology_uint8, 5)\n","\n","    contours, num_contours, img_contour = find_and_draw_contours(img_thresh)\n","\n","    segmented_image = segment_image(img, contours)\n","\n","    # Update the images in the existing axes\n","    plot_images(axs, idx, img_gray, img_blurred, img_equalized, img_morphology, img_thresh, img_contour, segmented_image, num_contours)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_y2Y9CFV-3F6rKQ-oINIGQszdK49Pmr9"},"id":"nv_amnVK0ukp","executionInfo":{"status":"ok","timestamp":1710052971842,"user_tz":-480,"elapsed":6954,"user":{"displayName":"Lisa Ho","userId":"02231809069531015548"}},"outputId":"93143a2c-855a-4159-eff7-bd5fda22440f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}