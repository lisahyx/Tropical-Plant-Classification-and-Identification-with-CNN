{"cells":[{"cell_type":"markdown","metadata":{"id":"hqPov1z0jusR","tags":[]},"source":["# Data Handling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlGhMNJmaPct"},"outputs":[],"source":["# Function to display array shapes in a table\n","def display_array_shapes(images, labels):\n","    # Get the shapes of the arrays\n","    image_shape = images.shape\n","    label_shape = labels.shape\n","\n","    # Create a list of data to display in the table\n","    data = [(\"Images\", image_shape), (\"Labels\", label_shape)]\n","\n","    # Print the data in a tabular format\n","    table = tabulate(data, headers=[\"Array Name\", \"Shape\"], tablefmt=\"grid\")\n","    print(table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxXGpfrvlk3l"},"outputs":[],"source":["from sklearn.preprocessing import LabelBinarizer\n","\n","# Function to binarize labels\n","def binarize_labels(labels):\n","    label_binarizer = LabelBinarizer()\n","    labels_binarized = label_binarizer.fit_transform(labels)\n","    return labels_binarized"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5jigQ6Dd58ey"},"outputs":[],"source":["from collections import Counter\n","\n","# Function to print label counts\n","def display_label_counts(label_counts):\n","    print(\"Label\\tCount\")\n","    print(\"----------------\")\n","    for label, count in label_counts.items():\n","        print(f\"{label}\\t{count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7BjI54TCOFS"},"outputs":[],"source":["from skimage.transform import resize\n","\n","# Function to resize images\n","def resize_images(images, image_size):\n","    # Check if images is a numpy array\n","    if not isinstance(images, np.ndarray):\n","        images = np.array(images)\n","\n","    # Initialize list to store preprocessed images\n","    preprocessed_images = []\n","\n","    for img in images:\n","        # Resize image\n","        img = resize(img, image_size)\n","\n","        preprocessed_images.append(img)\n","\n","    # Return preprocessed images as a numpy array\n","    return np.array(preprocessed_images)"]},{"cell_type":"markdown","metadata":{"id":"mMDOQOBD58ey"},"source":["# Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaxijtuI58ey"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","def augment_data(images, labels, label_counts, augmentation_factor=3):\n","    # Find labels with less than 75 images\n","    labels_to_augment = [label for label, count in label_counts.items() if count < 75]\n","\n","    # Create an ImageDataGenerator for augmentation\n","    datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        fill_mode='nearest'\n","    )\n","\n","    # Augment images\n","    augmented_images = []\n","    augmented_labels = []\n","\n","    for label in labels_to_augment:\n","        label_indices = np.where(labels == label)[0]\n","        images_to_augment = images[label_indices]\n","        for _ in range(augmentation_factor):\n","            for image in images_to_augment:\n","                augmented_image = datagen.random_transform(image)\n","                augmented_images.append(augmented_image)\n","                augmented_labels.append(label)\n","\n","    # Convert the lists to NumPy arrays\n","    augmented_images = np.array(augmented_images)\n","    augmented_labels = np.array(augmented_labels)\n","\n","    # Display the counts of the augmented labels\n","    print(\"Label\\tCount\")\n","    print(\"----------------\")\n","    for label in labels_to_augment:\n","        count = np.sum(augmented_labels == label)\n","        print(f\"{label}\\t{count}\")\n","\n","    return augmented_images, augmented_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a08vImoY58ez"},"outputs":[],"source":["def combine_augmented_data(images, labels, augmented_images, augmented_labels):\n","    # Find labels with less than 75 images\n","    labels_to_augment = [label for label, count in label_counts.items() if count < 75]\n","\n","    # Find indices of labels to augment\n","    indices_to_augment = np.where(np.isin(labels, labels_to_augment))[0]\n","\n","    # Remove original images and labels that are being augmented\n","    images_remaining = np.delete(images, indices_to_augment, axis=0)\n","    labels_remaining = np.delete(labels, indices_to_augment, axis=0)\n","\n","    # Combine the augmented images and labels with the remaining images and labels\n","    augmented_images_combined = np.concatenate((images_remaining, augmented_images))\n","    augmented_labels_combined = np.concatenate((labels_remaining, augmented_labels))\n","\n","    # Shuffle the combined data\n","    shuffle_indices = np.random.permutation(len(augmented_labels_combined))\n","    augmented_images_combined_shuffled = augmented_images_combined[shuffle_indices]\n","    augmented_labels_combined_shuffled = augmented_labels_combined[shuffle_indices]\n","\n","    # Verify the shapes of the combined arrays\n","    print(\"Original images shape:\", images.shape)\n","    print(\"Original labels shape:\", labels.shape)\n","    print(\"Augmented images shape:\", augmented_images.shape)\n","    print(\"Augmented labels shape:\", augmented_labels.shape)\n","    print(\"Remaining images shape:\", images_remaining.shape)\n","    print(\"Remaining labels shape:\", labels_remaining.shape)\n","    print(\"Augmented images combined shape:\", augmented_images_combined.shape)\n","    print(\"Augmented labels combined shape:\", augmented_labels_combined.shape)\n","\n","    return augmented_images_combined_shuffled, augmented_labels_combined_shuffled"]},{"cell_type":"markdown","metadata":{"id":"WI66wpR_58ez"},"source":["# Graph Plotting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVyUpSRBYdyj"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Function to plot training history\n","def plot_training_history(history):\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Loss Over Time')\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracy Over Time')\n","    plt.legend()\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uCURGYAc2PHr","tags":[]},"source":["# Building CNN Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD8WSzWwaTrW"},"outputs":[],"source":["# Function to build and compile the VGG19 model\n","def build_and_compile_vgg19_model(num_classes):\n","    # Load the VGG19 model with pre-trained weights and exclude the top classification layer\n","    vgg19_base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","\n","    # Freeze the pre-trained layers\n","    for layer in vgg19_base_model.layers:\n","        layer.trainable = False\n","\n","    # Create the final classification layers\n","    x = tf.keras.layers.Flatten()(vgg19_base_model.output)\n","    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    # Create the final model\n","    vgg19_model = tf.keras.Model(inputs=vgg19_base_model.input, outputs=predictions)\n","\n","    # Compile the model\n","    vgg19_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return vgg19_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5G5DZMymaYXJ"},"outputs":[],"source":["# Function to build and compile the ResNet101 model\n","def build_and_compile_resnet101_model(num_classes):\n","    # Load the ResNet101 model with pre-trained weights and exclude the top classification layer\n","    resnet101_base_model = tf.keras.applications.ResNet101(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","\n","    # Freeze the pre-trained layers\n","    for layer in resnet101_base_model.layers:\n","        layer.trainable = False\n","\n","    # Create the final classification layers\n","    x = tf.keras.layers.Flatten()(resnet101_base_model.output)\n","    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    # Create the final model\n","    resnet101_model = tf.keras.Model(inputs=resnet101_base_model.input, outputs=predictions)\n","\n","    # Compile the model\n","    resnet101_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return resnet101_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2uduDTQacpJ"},"outputs":[],"source":["# Function to build and compile the InceptionV3 model\n","def build_and_compile_inceptionv3_model(num_classes):\n","    # Load the InceptionV3 model with pre-trained weights and exclude the top classification layer\n","    inceptionv3_base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(299, 299, 3))\n","\n","    # Freeze the pre-trained layers\n","    for inceptionv3_layer in inceptionv3_base_model.layers:\n","        inceptionv3_layer.trainable = False\n","\n","    # Create the final classification layers\n","    x = tf.keras.layers.Flatten()(inceptionv3_base_model.output)\n","    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    # Create the final model\n","    inceptionv3_model = tf.keras.Model(inputs=inceptionv3_base_model.input, outputs=predictions)\n","\n","    # Compile the model\n","    inceptionv3_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return inceptionv3_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyaI4h8mBO_N"},"outputs":[],"source":["# Function to build and compile the MobileNetV2 model\n","def build_and_compile_mobilenetv2_model(num_classes):\n","    # Load the MobileNetV2 model with pre-trained weights and exclude the top classification layer\n","    mobilenetv2_base_model = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","\n","    # Freeze the pre-trained layers\n","    for mobilenetv2_layer in mobilenetv2_base_model.layers:\n","        mobilenetv2_layer.trainable = False\n","\n","    # Create the final classification layers\n","    x = tf.keras.layers.Flatten()(mobilenetv2_base_model.output)\n","    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    # Create the final model\n","    mobilenetv2_model = tf.keras.Model(inputs=mobilenetv2_base_model.input, outputs=predictions)\n","\n","    # Compile the model\n","    mobilenetv2_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return mobilenetv2_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdFDVc48BrFb"},"outputs":[],"source":["# Function to build and compile the EfficientNet model\n","def build_and_compile_efficientnet_model(num_classes):\n","    # Load the EfficientNetB0 model with pre-trained weights and exclude the top classification layer\n","    efficientnet_base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","\n","    # Freeze the pre-trained layers\n","    for efficientnet_layer in efficientnet_base_model.layers:\n","        efficientnet_layer.trainable = False\n","\n","    # Create the final classification layers\n","    x = tf.keras.layers.Flatten()(efficientnet_base_model.output)\n","    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    # Create the final model\n","    efficientnet_model = tf.keras.Model(inputs=efficientnet_base_model.input, outputs=predictions)\n","\n","    # Compile the model\n","    efficientnet_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return efficientnet_model"]},{"cell_type":"markdown","metadata":{"id":"14Q_y-pF2UH6","tags":[]},"source":["# Evaluating Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkOnE9981xHC"},"outputs":[],"source":["# Function to get predictied and true labels lists\n","def make_predictions_and_evaluate(model, X_data, y_true):\n","    # Set the model to evaluation mode\n","    model.evaluate(X_data, y_true)\n","\n","    # Make predictions on the dataset\n","    predicted_probabilities = model.predict(X_data)\n","\n","    # Convert predicted probabilities to class labels\n","    predicted_labels = np.argmax(predicted_probabilities, axis=1)\n","\n","    # Convert true labels to a list\n","    true_labels_list = np.argmax(y_true, axis=1)\n","\n","    return predicted_labels, true_labels_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbuhgBnQ7K4h"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","\n","# Function to calculate classification metrics\n","def calculate_classification_metrics(true_labels_list, predicted_labels):\n","    # Calculate precision, recall, and F1 score for each class\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        true_labels_list,\n","        predicted_labels,\n","        average=None,\n","        zero_division=0\n","    )\n","\n","    # Calculate average precision, recall, and F1 score\n","    avg_precision = precision.mean()\n","    avg_recall = recall.mean()\n","    avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n","\n","    # Calculate accuracy\n","    accuracy = accuracy_score(true_labels_list, predicted_labels)\n","\n","    # Print the average metrics\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {avg_precision:.4f}\")\n","    print(f\"Recall: {avg_recall:.4f}\")\n","    print(f\"F1 Score: {avg_f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2phGjw1saVkJ"},"outputs":[],"source":["# Function to display confusion matrix\n","def display_confusion_matrix(true_labels_list, predicted_labels):\n","    confusion = confusion_matrix(true_labels_list, predicted_labels)\n","\n","    # Display confusion matrix as a heatmap\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', cbar=False)\n","\n","    # Set ticks at positions 1, 2, ..., n\n","    classes = range(1, len(confusion) + 1)\n","    plt.xticks(classes, labels=classes)\n","    plt.yticks(classes, labels=classes)\n","\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":0}